{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpZjPKj2do7rxCrwOizRNN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glitcher007/RJPOLICE_HACK_1430_404_error_4/blob/main/nltk_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OLj-k7NdxSD4"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec,KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuiwtE0VxdGq",
        "outputId": "23ce06cd-c776-4508-d0c7-6e0929393fac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=59c6762e34a95ff43fba9212229bbddf5537f00c2cc073109e821694173da6d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBIZb_fy0guf",
        "outputId": "1995cc38-4c33-4bc0-b9b1-ce2d9410d06e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    split sentence into array of words/tokens\n",
        "    a token can be a word or punctuation character, or number\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)"
      ],
      "metadata": {
        "id": "gQOBPk6h1bOj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(word):\n",
        "    \"\"\"\n",
        "    stemming = find the root form of the word\n",
        "    examples:\n",
        "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
        "    words = [stem(w) for w in words]\n",
        "    -> [\"organ\", \"organ\", \"organ\"]\n",
        "    \"\"\"\n",
        "    return stemmer.stem(word.lower())"
      ],
      "metadata": {
        "id": "6p47iqcw20Lr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "# all the google news data is stored as api\n",
        "# here wv word vector stores all the vector\n",
        "# basically an improvement of bag of words it can diffrentiate between two similar words\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "\n",
        "vec_king = wv['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3D2JKRZxfxz",
        "outputId": "a2953264-4237-4942-b875-aa774cc4180b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Example of a pre-trained Word2Vec model (you should replace this with your actual model)\n",
        "word2vec_model = Word2Vec.load(\"path/to/your/model\")\n",
        "# write path of model here for train data\n",
        "\n",
        "def bag_of_words_to_word2vec(bag_of_words, model):\n",
        "    word2vec_array = np.zeros((len(bag_of_words), model.vector_size), dtype=np.float32)\n",
        "    for idx, value in enumerate(bag_of_words):\n",
        "        if value == 1:  # Check if the word is present in the bag of words\n",
        "            word = words[idx]  # Get the corresponding word\n",
        "            if word in model.wv:  # Check if the word is in the Word2Vec vocabulary\n",
        "                word2vec_array[idx] = model.wv[word]\n",
        "    return word2vec_array\n"
      ],
      "metadata": {
        "id": "ndlyF3qXxr9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIroVM9x2eBi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}